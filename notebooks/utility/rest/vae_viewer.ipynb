{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE viewer notebook for JetBot\n",
    "===\n",
    "\n",
    "This notebook can visualize reconstructioned image by vae. This repository using JetBot camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "import cv2\n",
    "import urllib\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from vae import VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Parameters\n",
    "\n",
    "|Name | Description| Default|\n",
    "|:----|:-----------|:-------|\n",
    "|IMAGE_CHANNELS | Image channel such as RGB | 3 Not change|\n",
    "|VARIANTS_SIZE  | Variants size of VAE      | 32          |\n",
    "|MODEL_PATH     | Trained VAE model file path | ../../vae.torch|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_CHANNELS = 3\n",
    "VARIANTS_SIZE = 32\n",
    "MODEL_PATH = '../../../vae.torch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained VAE model\n",
    "Loading trained VAE model on GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (7): ReLU()\n",
       "    (8): Flatten()\n",
       "  )\n",
       "  (fc1): Linear(in_features=6144, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=6144, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=6144, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): UnFlatten()\n",
       "    (1): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (6): ReLU()\n",
       "    (7): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (8): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "vae = VAE(image_channels=IMAGE_CHANNELS, z_dim=VARIANTS_SIZE)\n",
    "vae.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(device)))\n",
    "vae.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocess and postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    observe = PIL.Image.fromarray(image)\n",
    "    observe = observe.resize((160,120))\n",
    "    croped = observe.crop((0, 40, 160, 120))\n",
    "    tensor = transforms.ToTensor()(croped)\n",
    "    return tensor\n",
    "\n",
    "def preprocess_without_crop(image):\n",
    "    observe = PIL.Image.fromarray(image)\n",
    "    croped = observe.crop((0, 40, 320, 240))\n",
    "    tensor = transforms.ToTensor()(croped)\n",
    "    return tensor\n",
    "    \n",
    "def rgb8_to_jpeg(image):\n",
    "    return bytes(cv2.imencode('.jpg', image)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize latent space function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABS_LATENT_MAX_VALUE = 3\n",
    "PANEL_HEIGHT = 10\n",
    "PANEL_WIDTH = 10\n",
    "\n",
    "def sigmoid(x, gain=1, offset_x=0):\n",
    "    return ((np.tanh(((x+offset_x)*gain)/2)+1)/2)\n",
    "\n",
    "def color_bar_rgb(x):\n",
    "    gain = 10\n",
    "    offset_x= 0.2\n",
    "    offset_green = 0.6\n",
    "    x = (x * 2) - 1\n",
    "    red = sigmoid(x, gain, -1*offset_x)\n",
    "    blue = 1-sigmoid(x, gain, offset_x)\n",
    "    green = sigmoid(x, gain, offset_green) + (1-sigmoid(x,gain,-1*offset_green))\n",
    "    green = green - 1.0\n",
    "    return [blue * 255,green * 255,red * 255]\n",
    "\n",
    "def _get_color(value):\n",
    "    t = (value + ABS_LATENT_MAX_VALUE) / (ABS_LATENT_MAX_VALUE * 2.0)\n",
    "    color = color_bar_rgb(t)\n",
    "    return color\n",
    "\n",
    "def create_color_panel(latent_spaces):\n",
    "    images = []\n",
    "    for z in latent_spaces:\n",
    "        p = np.zeros((PANEL_HEIGHT, PANEL_WIDTH, 3))\n",
    "        color = _get_color(z)\n",
    "        p += color[::-1]\n",
    "        p = np.clip(p, 0, 255)\n",
    "        images.append(p)\n",
    "    panel = np.concatenate(images, axis=1)\n",
    "    return panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Jetbot IP and port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetbot_ip = 'localhost'\n",
    "jetbot_port = 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2cbabd4c7e4724bb7e877700d3ee7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', height='80', width='160'), Image(value=b'', format='jpeg', heigâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a50d2059da6466f8b2f9263cc482346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='100', width='320')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = widgets.Image(format='jpeg', width=160, height=80)\n",
    "result = widgets.Image(format='jpeg', width=160, height=80)\n",
    "color_bar = widgets.Image(format='jpeg', width=32*PANEL_WIDTH, height=10*PANEL_HEIGHT)\n",
    "display(widgets.HBox([resize,result]))\n",
    "display(color_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start cell over and over to see reconstruction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_process(img):\n",
    "    pil_image = preprocess_without_crop(img)\n",
    "    preprocessed_image = preprocess(img)\n",
    "    resize.value = rgb8_to_jpeg(np.transpose(np.uint8(preprocessed_image*255),[1,2,0]))\n",
    "    z, _ ,_ = vae.encode(torch.unsqueeze(preprocessed_image,dim=0).to(device))\n",
    "    reconst = vae.decode(z)\n",
    "    reconst = reconst.detach().cpu()[0].numpy()\n",
    "    # Change reconstruction image to RGB\n",
    "    reconst = np.transpose(np.uint8(reconst*255),[1,2,0])[:,:,::-1]\n",
    "    result.value = rgb8_to_jpeg(reconst)\n",
    "    latent_space = z.detach().cpu().numpy()[0]\n",
    "    color_bar.value = rgb8_to_jpeg(create_color_panel(latent_space))\n",
    "\n",
    "req = urllib.request.urlopen('http://{0}:{1}/camera'.format(jetbot_ip,jetbot_port))\n",
    "arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "img = cv2.imdecode(arr, -1)\n",
    "vae_process(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
